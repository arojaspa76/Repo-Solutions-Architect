# Comparative table of patterns
Summary for use in an architectural slide or document:

| Patrón                                       | Qué resuelve                                          | Ventajas                                                                                              | Desventajas                                                        | Cuándo usarlo                                                        | Tecnologías donde brilla                                                                            |
| -------------------------------------------- | ----------------------------------------------------- | ----------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------ | -------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| **Prompt / CoT / Few-shot**                  | Controlar comportamiento del modelo sin cambiar pesos | Rápido, barato, flexible                                                                              | Difícil de versionar si no hay disciplina, puede ser frágil        | MVPs, prototipos, ajuste fino de tono/rol                            | Todos: Azure OpenAI, Bedrock, Vertex, NIMs, Open-source                                             |
| **RAG básico**                               | Acceder a conocimiento actualizado / privado          | Reduce alucinaciones, no requiere retraining, permite citar fuentes ([Wikipedia][1])                  | Requiere buena calidad de datos, ingeniería de chunking            | FAQs, knowledge bases, portales internos, documentación técnica      | Azure AI Search + AOAI, Bedrock KB, Vertex Search + Gemini, Milvus/Pinecone + NIMs                  |
| **RAG avanzado (multi-step, reranking, KG)** | Preguntas complejas y documentos grandes              | Mejor relevancia, maneja relaciones complejas                                                         | Mayor latencia y complejidad                                       | Asistentes legales, médicos, compliance, arquitectura cloud          | LangGraph/LlamaIndex con Azure/Bedrock/Vertex, NIMs en on-prem                                      |
| **ReAct / Tool Calling**                     | Integrar LLM con APIs, DBs, acciones                  | Framework unificado de razonamiento + acción, base de agentes modernos ([arXiv][2])                   | Difícil de testear, riesgo si herramientas hacen cambios críticos  | Automatización, asistentes de TI, DevOps, finanzas                   | Azure function calling, Bedrock Agents, Gemini code execution, MCP, NIMs + microservicios           |
| **PAL / Code-as-Reasoning**                  | Matemáticas, lógica, data wrangling precisos          | Mucha más exactitud, auditable, usa ecosistemas como Python/SQL ([CMU School of Computer Science][3]) | Riesgo de código inseguro si no hay sandbox, más complejidad infra | Análisis de datos, ETL con IA, reasoning complejo                    | Gemini Code Execution, OpenAI/Claude code interpreter, NIMs + Python/TensorRT                       |
| **Multi-Agent / Orchestrator-Worker**        | Tareas largas y heterogéneas, workflows complejos     | Escalabilidad lógica, separación de responsabilidades ([Microsoft][4])                                | Debugging complejo, control de coste más difícil                   | Sistemas tipo “AI copilot para toda la empresa”                      | Microsoft Agent Framework, AutoGen, LangGraph, Bedrock AgentCore, Vertex agents                     |
| **Fine-Tuning / LoRA**                       | Especializar modelo en dominio/estilo                 | Mejor estilo, menor dependencia del prompt, puede correr en edge                                      | Caro (según tamaño), riesgo de sobre-especialización               | Dominios muy específicos (legal, oil&gas, medicina), modelos on-prem | TensorRT-LLM + LoRA en NIMs/Jetson, Vertex Custom Models, Bedrock fine-tuning                       |
| **Guardrails / Safety / Policies**           | Cumplimiento, moderación, PII, políticas internas     | Imprescindible en enterprise, separa lógica de negocio de LLM                                         | Puede bloquear demasiado, requiere tuning constante                | Bancos, salud, gobierno, HR, datos sensibles                         | Bedrock Guardrails, Azure AI Content Safety, NIM Multimodal Safety, soluciones de terceros          |
| **Caching**                                  | Coste/latencia con tráfico repetitivo                 | Ahorros grandes, mejor UX                                                                             | Cache invalidation es hard, requiere estrategia de TTL             | Q&A recurrente, plantillas repetidas de reporting                    | Redis/KeyDB front-end a cualquier proveedor, APIs de cache internas                                 |
| **Dynamic Model Selection / Distillation**   | Balance costo-calidad en producción                   | Optimiza factura, permite usar modelos pequeños en edge                                               | Añade orquestación y más lógica                                    | Sistemas de alto tráfico, mobile/edge, IoT industrial                | Routers con LangGraph / Semantic Router, NIMs + pequeños LLM en Jetson, Vertex Router-like patterns |

[1]: https://en.wikipedia.org/wiki/Retrieval-augmented_generation?utm_source=chatgpt.com "Retrieval-augmented generation"
[2]: https://arxiv.org/abs/2210.03629?utm_source=chatgpt.com "Synergizing Reasoning and Acting in Language Models"
[3]: https://www.cs.cmu.edu/~callan/Papers/icml23-Luyu-Gao.pdf?utm_source=chatgpt.com "PAL: Program-aided Language Models"
[4]: https://www.microsoft.com/en-us/research/project/autogen/?utm_source=chatgpt.com "AutoGen - Microsoft Research"
